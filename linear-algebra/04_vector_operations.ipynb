{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Operations: Scalar Multiplication, Sum and Dot Product of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Scalar Multiplication and Sum of Vectors\n",
    "Vectors are represented by arrows in mathematics. Below we can see the arrow representation of a vector in Cartesian coordinates.\n",
    "\n",
    "a $v\\in\\mathbb{R}^2$, e.g.\n",
    "$v=\\begin{bmatrix}\n",
    "          1 & 3\n",
    "\\end{bmatrix}^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vectors(list_v, list_label, list_color):\n",
    "    _, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.set_xticks(np.arange(-10, 10))\n",
    "    ax.set_yticks(np.arange(-10, 10))\n",
    "    \n",
    "    \n",
    "    plt.axis([-10, 10, -10, 10])\n",
    "    for i, v in enumerate(list_v):\n",
    "        sgn = 0.4 * np.array([[1] if i==0 else [i] for i in np.sign(v)])\n",
    "        plt.quiver(v[0], v[1], color=list_color[i], angles='xy', scale_units='xy', scale=1)\n",
    "        ax.text(v[0]-0.2+sgn[0], v[1]-0.2+sgn[1], list_label[i], fontsize=14, color=list_color[i])\n",
    "\n",
    "    plt.grid()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "v = np.array([[1],[3]])\n",
    "# Arguments: list of vectors as NumPy arrays, labels, colors.\n",
    "plot_vectors([v], [f\"$v$\"], [\"black\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors are defined by their *__norm (length, magnitude)__* and *__direction__*, not by their position. However, vectors are plotted starting from the origin for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Scalar Multiplication\n",
    "The scalar multiplication of a vector is obtained by multiplying each of its elements by that scalar.\n",
    "\n",
    "For example, when vector $v=\\begin{bmatrix}\n",
    "          v_1 & v_2 & \\ldots & v_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$ is multiplied by scalar $k$, vector $kv=\\begin{bmatrix}\n",
    "          kv_1 & kv_2 & \\ldots & kv_n \n",
    "\\end{bmatrix}^T$ is obtained. If $k$ > 0, the resulting vector is in the same direction as vector $v$ and is $k$ times larger. If $k$ = 0, the zero vector is obtained. If $k$ < 0, the resulting vector is in the opposite direction to vector $v$ and is $k$ times larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vectors([v, 3*v, -3*v], [f\"$v$\", f\"$3v$\", f\"$-3v$\"], [\"black\", \"green\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Sum of Vectors\n",
    "\n",
    "*__Sum of vectors (vector addition)__* means adding up each element of the vectors. \n",
    "\n",
    "For example $v=\\begin{bmatrix}\n",
    "          v_1 & v_2 & \\ldots & v_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$ and  $w=\\begin{bmatrix}\n",
    "          w_1 & w_2 & \\ldots & w_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$, \n",
    "\n",
    "then $v + w=\\begin{bmatrix}\n",
    "          v_1 + w_1 & v_2 + w_2 & \\ldots & v_n + w_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$. This is the *__parallelogram law__*.\n",
    "\n",
    "<img src = \"images/vector_sum-001.png\" width=\"230\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([4, -1])\n",
    "b = np.array([1, 3])\n",
    "\n",
    "plot_vectors([a, b, np.add(a, b)], [f\"$a$\", f\"$b$\", f\"$a + b$\"], [\"black\", \"black\", \"red\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Norm of Vector\n",
    "\n",
    "The norm of a vector represents the *__length__* of that vector. The norm *__cannot be negative__*. Vector norm is calculated with numpy using the *__np.linalg.norm()__* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Norm of a vector a is\", np.linalg.norm(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dot Product\n",
    "\n",
    "The **dot product** (or **scalar product**) is an algebraic operation that takes two vectors $x=\\begin{bmatrix}\n",
    "          x_1 & x_2 & \\ldots & x_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$ and  \n",
    "$y=\\begin{bmatrix}\n",
    "          y_1 & y_2 & \\ldots & y_n \n",
    "\\end{bmatrix}^T\\in\\mathbb{R}^n$ and returns a single scalar. The dot product can be represented with a dot operator $x\\cdot y$ and defined as:\n",
    "\n",
    "$$x\\cdot y = \\sum_{i=1}^{n} x_iy_i = x_1y_1+x_2y_2+\\ldots+x_ny_n \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, -2, -5]\n",
    "y = [4, 3, -1]\n",
    "\n",
    "def dot(x,y):\n",
    "    s = 0\n",
    "    for xi, yi in zip(x, y):\n",
    "        s += xi * yi\n",
    "\n",
    "    return s\n",
    "\n",
    "print(\"The dot product of x and y is\", dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"np.dot(x,y) function returns dot product of x and y:\", np.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works even if we do not define vectors as numpy arrays. Another way to do dot product in Python is to use the @ operator. But this operator only works with numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This line output is a dot product of x and y: \", np.array(x) @ np.array(y))\n",
    "\n",
    "print(\"\\nThis line output is an error:\")\n",
    "try:\n",
    "    print(x @ y)\n",
    "except TypeError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product is calculated using large data sets and multidimensional vectors in Machine Learning applications. For this reason, performance is very important. We can compare the dot() function, np.dot() and the @ operator and see which one is more performant.\n",
    "\n",
    "In the loop form operations are performed one by one, while in the vectorized form they can be performed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "c = dot(a,b)\n",
    "toc = time.time()\n",
    "print(\"Dot product: \", c)\n",
    "print (\"Time for the loop version:\" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print(\"Dot product: \", c)\n",
    "print (\"Time for the vectorized version, np.dot() function: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "c = a @ b\n",
    "toc = time.time()\n",
    "print(\"Dot product: \", c)\n",
    "print (\"Time for the vectorized version, @ function: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Geometric Definition of the Dot Product\n",
    "\n",
    "In Euclidean space, a Euclidean vector has both length and direction. Dot product of two vectors in Euclidean space:\n",
    "\n",
    "$$x\\cdot y = \\lvert x\\rvert \\lvert y\\rvert \\cos(\\theta),\\tag{2}$$  \n",
    "where  ùúÉ is the angle between the two vectors:\n",
    "\n",
    "<img src=\"images/dot-product.svg\">\n",
    "\n",
    "If these two vectors are orthogonal , then since cos(90) = 0,  it implies that the dot product of any two orthogonal vectors must be  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.array([1, 0, 0])\n",
    "j = np.array([0, 1, 0])\n",
    "print(\"The dot product of i and j is\", dot(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Application of the Dot Product: Vector Similarity\n",
    "\n",
    "Geometric definition of a dot product is used in one of the applications - to evaluate **vector similarity**. In Natural Language Processing (NLP) words or phrases from vocabulary are mapped to a corresponding vector of real numbers. Similarity between two vectors can be defined as a cosine of the angle between them. When they point in the same direction, their similarity is 1 and it decreases with the increase of the angle. \n",
    "\n",
    "Then equation $(2)$ can be rearranged to evaluate cosine of the angle between vectors:\n",
    "\n",
    "$\\cos(\\theta)=\\frac{x \\cdot y}{\\lvert x\\rvert \\lvert y\\rvert}$\n",
    "\n",
    "Zero value corresponds to the zero similarity between vectors (and words corresponding to those vectors). Largest value is when vectors point in the same direction, lowest value is when vectors point in the opposite directions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
